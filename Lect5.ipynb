{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lect 5 : Scikit Learn : Supervised Learning and Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning - Classification & Regression\n",
    "In **Supervised Learning**, we have a dataset consisting of both features and labels.\n",
    "The task is to construct an estimator which is able to predict the label of an object\n",
    "given the set of features. A relatively simple example is predicting the species of \n",
    "iris given a set of measurements of its flower. This is a relatively simple task. \n",
    "\n",
    "Some more complicated examples are:\n",
    "\n",
    "- given a multicolor image of an object through a telescope, determine\n",
    "  whether that object is a star, a quasar, or a galaxy.\n",
    "- given a photograph of a person, identify the person in the photo.\n",
    "- given the history of items that you have purchased from Amazon, provide recommendations for items that you are most like to buy next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recap of LinearRegression model.\n",
    "\n",
    "#Create some noisy data. \n",
    "np.random.seed(0)\n",
    "X = np.random.random(size=(20, 1))\n",
    "y = 3 * X.squeeze() + 2 + np.random.randn(20)\n",
    "\n",
    "plt.plot(X.squeeze(), y, 'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the LinearRegression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Intantiate the estimator object : i.e., model with some parameters.\n",
    "model = LinearRegression()\n",
    "\n",
    "#Use the fit method of the model object.\n",
    "model.fit(X, y)\n",
    "\n",
    "#Get some new X data whose y values need to be predicted\n",
    "X_f = np.linspace(0.0,1.0,100)[:,np.newaxis]\n",
    "\n",
    "# Predict the y values for the new X data\n",
    "y_f = model.predict(X_f)\n",
    "\n",
    "plt.plot(X.squeeze(), y, 'ro')\n",
    "plt.plot(X_f.squeeze(), y_f, 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the RandomForestRegression class\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Intantiate the estimator object : i.e., model with some parameters.\n",
    "\n",
    "\n",
    "#Use the fit method of the model object.\n",
    "\n",
    "\n",
    "#Get some new X data whose y values need to be predicted\n",
    "\n",
    "\n",
    "# Predict the y values for the new X data\n",
    "\n",
    "\n",
    "# Plot the data along with the fit. \n",
    "plt.plot(X.squeeze(), y, 'ro')\n",
    "plt.plot(X_f.squeeze(), y_f, 'k-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "\n",
    "For Polynomial regression there exsits a nice extrapolation to Linear Regression. It involves *sklearn.preprocessing* and *sklearn.pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model  import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Intantiate the estimator object : i.e., model with some parameters.\n",
    "model =Pipeline([('poly',PolynomialFeatures(degree=3)), \n",
    "        ('linear', LinearRegression(fit_intercept=False))])\n",
    "\n",
    "#Create some data \n",
    "X = np.arange(45)\n",
    "y = 3.0 - 2.0*X + 5.0*X*X + 0.75*X*X*X\n",
    "\n",
    "#Use the fit method of the model object.\n",
    "model.fit(X[:,np.newaxis], y)\n",
    "\n",
    "#print the coeffs.\n",
    "model.named_steps['linear'].coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format in Scikit Learn\n",
    "\n",
    "Most machine learning algorithms implemented in scikit-learn expect data to be stored in a\n",
    "**two-dimensional array or matrix**.  The arrays can be\n",
    "either ``numpy`` arrays, or in some cases ``scipy.sparse`` matrices.\n",
    "The size of the array is expected to be `[n_samples, n_features]`\n",
    "\n",
    "- **n_samples:**   The number of samples: each sample is an item to process (e.g. classify).\n",
    "  A sample can be a document, a picture, a sound, a video, an astronomical object,\n",
    "  a row in database or CSV file,\n",
    "  or whatever you can describe with a fixed set of quantitative traits.\n",
    "- **n_features:**  The number of features or distinct traits that can be used to describe each\n",
    "  item in a quantitative manner.  Features are generally real-valued, but may be boolean or\n",
    "  discrete-valued in some cases.\n",
    "\n",
    "\n",
    "A simple dataset that we will look is the Iris dataset. This is very widely used in all tutorials to explain the basic principle of machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Iris Data with Scikit-Learn\n",
    "\n",
    "Scikit-learn has a very straightforward set of data on these iris species.  The data consist of\n",
    "the following:\n",
    "\n",
    "- Features in the Iris dataset:\n",
    "\n",
    "  1. sepal length in cm\n",
    "  2. sepal width in cm\n",
    "  3. petal length in cm\n",
    "  4. petal width in cm\n",
    "\n",
    "- Target classes to predict:\n",
    "\n",
    "  1. Iris Setosa\n",
    "  2. Iris Versicolour\n",
    "  3. Iris Virginica\n",
    "  \n",
    "``scikit-learn`` embeds a copy of the iris CSV file along with a helper function to load it into numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Information about the data\n",
    "print iris.data.shape\n",
    "print iris.feature_names\n",
    "print iris.target_names\n",
    "print iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_index = 0\n",
    "y_index = 1\n",
    "\n",
    "# this formatter will label the colorbar with the correct target names\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index],\n",
    "            c=iris.target, cmap=plt.cm.get_cmap('RdYlBu', 3))\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.clim(-0.5, 2.5)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise. \n",
    "\n",
    "Try to play with the combination of features where you would see the maximum separation with eye in the data.\n",
    "\n",
    "\n",
    "### More Data. \n",
    "\n",
    "Scikit Learn has three types of data from various domains available for exercises and learning. \n",
    "\n",
    "- **Packaged data** : datasets.load_..\n",
    "- **Downloadable data** : datasets.fetch_..\n",
    "- **Customized data**   : datasets.make_.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using K-NearestNeighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "#Intantiate the estimator object : i.e., model with some parameters.\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Use the fit method of the model object.\n",
    "X, y = iris.data, iris.target\n",
    "model.fit(X, y)\n",
    "\n",
    "#Get some new X data whose y values need to be predicted\n",
    "X_f = np.array([[3,5,4,2],])\n",
    "\n",
    "\n",
    "# Predict the y values for the new X data\n",
    "y_f = model.predict(X_f)\n",
    "print iris.target_names[y_f]\n",
    "\n",
    "model.predict_proba(X_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]  # we only take the first two features. \n",
    "y = iris.target\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X, y)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                    np.linspace(y_min, y_max, 100))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "#Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z,alpha=0.4)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "ax = plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Classify the Iris datasets using the Support Vector Classifier.\n",
    "*from sklearn.svm import SVC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#Intantiate the estimator object : i.e., model with some parameters.\n",
    "\n",
    "\n",
    "#Use the fit method of the model object.\n",
    "\n",
    "\n",
    "#Get some new X data whose y values need to be predicted\n",
    "\n",
    "\n",
    "# Predict the y values for the new X data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation -- Tip of Iceberg. \n",
    "\n",
    "Now it makes absolute sense to verify which of the models perform better and how can we optimize the values of the parameters to be given to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X, y = iris.data, iris.target\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "print(np.all(y == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Confusion matrix a measure of score for the Classifier.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Train data sets. \n",
    "\n",
    "The model has to be trained on a subset of data and then tested on the rest. BUT!! How to split the test and train so that the splitting makes statistically some sense (mixed sample). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y)\n",
    "print Xtr.shape, Xte.shape\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=7)\n",
    "clf.fit(Xtr, ytr)\n",
    "ypred = clf.predict(Xte)\n",
    "print (confusion_matrix(yte, ypred))\n",
    "print (accuracy_score(yte, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application for Reading Digits. - Optical Character Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='green')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The images themselves\n",
    "print(digits.images.shape)\n",
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(digits.data.shape)\n",
    "print(digits.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a data of size 1797 hand-written numbers and each number has 64 pixel values.\n",
    "\n",
    "## Exercise Task. \n",
    "Use the *LogisticRegression* Classifier and apply the cross-validation method that we learned to get the accuracy score and also display the confusion matrix using the following plot command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your LogisticRegression Classifier model. \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.log(confusion_matrix(yte, ypred)),\n",
    "           cmap='Blues', interpolation='nearest')\n",
    "plt.grid(False)\n",
    "plt.ylabel('true')\n",
    "plt.xlabel('predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally see for yourself which numbers have not been correctly identified \n",
    "with your classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(Xte[i].reshape(8, 8), cmap='binary')\n",
    "    ax.text(0.05, 0.05, str(ypred[i]),\n",
    "            transform=ax.transAxes,\n",
    "            color='green' if (yte[i] == ypred[i]) else 'red')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
