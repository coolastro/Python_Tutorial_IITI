{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 : Reading, Writing and Plotting Datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lecture we studied a very memory efficient way of handling data values of same type packed in an object called *numpy.ndarray* using the module **Numpy**. \n",
    "\n",
    "We also saw how using notebook we were able to plot 1D curves using *matplotlib* and do annotation of axis, text, legend and so on. \n",
    "\n",
    "In the first part of this lecture we go back again to matplotlib to understand how to make 2D surface plots and then go ahead to I/O methods provided by *Python* and associated libraries. \n",
    "\n",
    "    **New Library Required** : csv, pyfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **MATPLOTLIB 2D IMAGING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a random 2D array\n",
    "mu, sigma = 3.0, 9.0\n",
    "D = mu + sigma*np.random.randn(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1 = plt.figure(figsize=[14,8], dpi=100)\n",
    "ax1 = plt.subplot(121)\n",
    "im1 = ax1.imshow(D, origin='image',extent=[0.0,60.0,0.0,60.0])   # USE WHEN MESH IS UNIFORM.\n",
    "plt.colorbar(im1,orientation='vertical', shrink=0.7)\n",
    "plt.xlabel(r'X axis')\n",
    "plt.ylabel(r'Y axis')\n",
    "plt.title(r'Normal Distributed Random $\\mu$ = 3.0, $\\sigma$ = 9.0')\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.plot(np.linspace(0.0,60.0,128), D[:,64], 'k-',lw=2)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_xlabel(r'X axis')\n",
    "ax2.set_title(r'Cut along the mid-plane')\n",
    "ax2.minorticks_on()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-2.0*np.pi, 2.0*np.pi,128)\n",
    "y = np.linspace(-2.0*np.pi, 2.0*np.pi,128)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.sin(X) + np.cos(Y)*np.sin(Y)*np.cos(X)*np.cos(X)\n",
    "\n",
    "im1 = plt.pcolormesh(x, y, Z)             # USED WHEN THE MESHGRID IS NON UNIFORM.\n",
    "plt.colorbar(im1)\n",
    "plt.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "plt.xlabel(r'X axis')\n",
    "plt.ylabel(r'Y axis')\n",
    "#plt.savefig(\"nameofpngfile.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discrete Fourier Transform with Numpy -- np.fft.\n",
    "np.fft?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no of sample points \n",
    "N = 600\n",
    "# Interval in time domain. \n",
    "T = 1./800.\n",
    "tm = np.linspace(0.0, N*T, N)\n",
    "sig = np.sin(50.0*2.0*np.pi*tm) + 0.5*np.sin(80.0*2.0*np.pi*tm)\n",
    "sigf = np.fft.fft(sig)\n",
    "freq = np.linspace(0.0, 1./(2.*T), N/2)\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(tm, sig, 'r',lw=2)\n",
    "ax2 = plt.subplot(212)\n",
    "ax2.plot(freq, (2./N)*np.abs(sigf[:N/2]), 'k', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I/O WITH PYTHON**\n",
    "\n",
    "The I/O routines provided by numpy to load data and write data to files are as follows.\n",
    "\n",
    "*Loading from file*\n",
    "\n",
    "**np.load**    ---     Load data from *.npy* or *.npz* file\n",
    "\n",
    "**np.loadtxt** ---     When no data is missing then use\n",
    "\n",
    "**np.genfromtxt** --- With missing data.\n",
    "\n",
    "**np.fromfile**   --- Read text from files.  \n",
    "\n",
    "*Writing to File*\n",
    "\n",
    "**np.save**           ---- Write single array in a binary file *.npy*  \n",
    "\n",
    "**np.savez**          ---- Write multiple arrays in a binary file *.npz* \n",
    "\n",
    "**np.ndarray.tofile** ---- Write data to a file as text or binary (default).  \n",
    "\n",
    "\n",
    "Apart from the above there are native python read and write functions that we will see. \n",
    "Additionally, we also have external libraries for reading a custom datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving and loading array\n",
    "a = np.diag([1.,-10., 2.0, 4.0])\n",
    "np.save('diagonal.npy', a)\n",
    "b = np.load('diagonal.npy')\n",
    "print a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading simple Text file with Ignoring Comments ::: NATIVE PYTHON AND LISTS.\n",
    "\n",
    "#Step 1 : Open the file of reading.\n",
    "fp = open('definitions.h', 'r')\n",
    "\n",
    "#Run a for loop for all lines.\n",
    "for line in fp.readlines():\n",
    "    print line\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 1 : Open the file of reading.\n",
    "fp = open('definitions.h', 'r')\n",
    "comment = []\n",
    "text    = []\n",
    "#Run a for loop for all lines.\n",
    "for line in fp.readlines():\n",
    "    scrh = line.split()\n",
    "    if len(scrh) > 0:\n",
    "        if scrh[0] == '/*':\n",
    "            comment.append(line)\n",
    "        else:\n",
    "            text.append(line)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "fp.close()\n",
    "\n",
    "#fc = open('def_comments.txt','w')\n",
    "#for l in comment:\n",
    "#    fc.write(l)\n",
    "#fc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To get header info. \n",
    "fp = open('POSB.csv','r')\n",
    "header = fp.readline().strip().split(',')   # Strip removes the '\\n' and splits breaks into components of a list.\n",
    "fp.close()\n",
    "\n",
    "#To get Data. \n",
    "D = np.loadtxt('POSB.csv',skiprows=1, delimiter=',')\n",
    "#for i in range(len(header)):\n",
    "#    print i, header[i]\n",
    "#print D.shape\n",
    "\n",
    "#To build a dictionary with key, value pairs.\n",
    "kvlist = []\n",
    "for i in range(len(header)): \n",
    "    kvlist.append((header[i].split('(')[0].strip(), D[:,i]))   # Here strip removes trailing spaces.\n",
    "Data = {}\n",
    "for k,v in kvlist:\n",
    "    Data[k] = v\n",
    "print Data.keys()\n",
    "\n",
    "plt.scatter(Data['X pos'], Data['speed'],s=100,marker='o',c=Data['speed'],cmap='copper')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading from CSV file. \n",
    "import csv\n",
    "with open('POSB.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    D = [row for row in reader]\n",
    "\n",
    "header = np.asarray(D[0])\n",
    "Data = np.asarray(D[1:])\n",
    "for i in range(len(header)):\n",
    "    print i, header[i]\n",
    "plt.scatter(Data[:,7], Data[:,15], marker='o',s=100,c=Data[:,15],cmap='copper')\n",
    "plt.xlabel(header[7])\n",
    "plt.ylabel(header[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Writing CSV file.\n",
    "\n",
    "f = open('dummy.csv', 'wb')\n",
    "try:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow( ('Title 1', 'Title 2', 'Title 3') )\n",
    "    for i in range(10):\n",
    "        writer.writerow( (i+1, chr(ord('a') + i), '08/%02d/17' % (i+1)) )\n",
    "finally:\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FITS FILE READING USING PYFITS**\n",
    "\n",
    "The pyfits is available at : http://www.stsci.edu/institute/software_hardware/pyfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyfits\n",
    "datalist = pyfits.open('example_beam_pattern_S0000_TIME_SEP_CHAN_SEP_AMP_YX.fits')\n",
    "print datalist.info()\n",
    "\n",
    "head = datalist[0].header\n",
    "data = datalist[0].data\n",
    "#print head.items()\n",
    "\n",
    "print len(data)\n",
    "im1 = plt.imshow(data[10][0,:,:], origin='image')\n",
    "plt.colorbar(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONVERTING .SAV FILES TO NUMPY ARRAYS**\n",
    "\n",
    "People using IDL would usually store their arrays in *.sav* files. This is equivalent to *.npy* Python save files that we saw eariler. These files are usually in binary format and one can read the same if the format is known before hand. \n",
    "\n",
    "Python *Scipy* also has some I/O routines and one of them is just decicated to reading *.sav* files generated from IDL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import readsav\n",
    "\n",
    "D = readsav('python_test_files.sav')   # Outputs a dictionary with the keys same as the variable names. \n",
    "print D.keys()\n",
    "\n",
    "plt.plot(D['x'], D['y1'], lw=2, c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
